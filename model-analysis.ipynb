{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self driving car model analysis\n",
    "\n",
    "The purpose of this analysis is try to explain the train and test proceses. Analysing data and augmentation this to improve accurary and later simulation over udacity simulator.\n",
    "\n",
    "Without further ado, let's start with the step-by-step process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Let's import required classes & functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from lib.config import Config\n",
    "from lib.dataset_loader import DatasetLoader\n",
    "from lib.model_factory import ModelFactory\n",
    "from lib.data_generator import SteeringWheelAngleDataGenerator\n",
    "from lib.image_preprocessor import ImagePreprocessor\n",
    "from lib.sample_augmenter import SampleAugmenter\n",
    "from lib.callback.callback_factory import CheckpointFactory, PlotLossesFactory\n",
    "from lib.image_utils import load_image, vertical_crop_image, resize_image, rgb_to_yuv\n",
    "from lib.plot_utils import show_image, show_distribution, show_sample\n",
    "from lib.image_augmentation_utils import choose_image, random_image_flip, \\\n",
    "                                         random_image_translate, random_image_shadow, \\\n",
    "                                         random_image_brightness\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: First of all check that has a GPU available. This is required to decrease learning training times: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU's:  []\n"
     ]
    }
   ],
   "source": [
    "print(\"Available GPU's: \", K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Load config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config('./config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was previously generater using de **Training Mode** of UDacity simulator. This mode generate:\n",
    "\n",
    "1. **IMG** directory that contain images taked with all cameras(left, center, right)\n",
    "\n",
    "2. **driving_log.csv** file that contain examples with next columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['dataset']['columns']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When:\n",
    "* **Center**, **Left** and **Right**: Are images paths. That images was taked from three cameras mounted in front of a car in the simulator.\n",
    "* **Steering**: The car steering whell angle.\n",
    "* **Throttle**: Car aceletation.\n",
    "* **Reverse**\n",
    "* **Speed**: Car speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DatasetLoader(cfg)\n",
    "\n",
    "dataset = loader.load(\n",
    "    features=cfg['dataset']['features'],\n",
    "    labels=cfg['dataset']['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Images\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "sample.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Show streering angle distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_distribution(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Split dataset in train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = dataset.split(percent=cfg['train']['validation_set_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train dataset examples: \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation dataset examples: \", len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NVidia model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can get as input an image and predict next steering whell angle of the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Define magic lambda that used to normalize images to avoid saturation and make gradients work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization=lambda x: x / 127.5 - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Next let's define the input shape given three parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = cfg['dataset']['image']['height']\n",
    "print('Input Image Height: ', image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = cfg['dataset']['image']['width']\n",
    "print('Input Image Width: ', image_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image channels refers to RGB color notation (red, green, blue):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels = cfg['dataset']['image']['channels']\n",
    "print('Input Image Channels: ', image_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define input shape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then an input shape is a tensor (a list of matrixes) of range 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(image_height, image_width, image_channels)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Next define 50% dropout after las CNN layer <a href='#1.-Dropout'>[1]</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_end_dropout_rate=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Also use an activation function ELU <a href='#2.-Activation-Functions'>[2]</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation='elu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelFactory.create_nvidia_model(\n",
    "    input_shape,\n",
    "    input_normalization,\n",
    "    cnn_end_dropout_rate,\n",
    "    activation\n",
    ")\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all is necessary explain three importante points:\n",
    "\n",
    "* A generator allow us to generator a dataset for augment and/or preprocess and in this way increase samples amount. \n",
    "* Since in most cases dataset does not fit in memory a generator allow as to save memory space, loading only a subset of this on each train batch.\n",
    "* A generator also allow us to process data using multiples cpu cores.\n",
    "\n",
    "On the other hand, data augmentation and preprocessing is required to improve model accuracy. Particularly for this problem is required two flows to generate samples:\n",
    "\n",
    "* **Train samples generation**:\n",
    "    * Augment & preprocess a randomly image from the center, left or right cameras.\n",
    "    * Preproress agmented image.\n",
    "    * Steering angles is adjustes in each case.\n",
    "\n",
    "* **Validation samples generation**: Only preprocess center camera image.\n",
    "\n",
    "But what does augmentation and preprocess means?\n",
    "        \n",
    "* **Augmentation steps**: \n",
    "    1. Randomly choose an image from the center, left or right, and adjust the steering angle.\n",
    "    2. Randomly flip the image left <-> right, and adjust the steering angle.\n",
    "    3. Randomly shift the image vertically and horizontally (translation).\n",
    "    4. Generates and adds random shadow.\n",
    "    5. Randomly adjust brightness of the image.\n",
    "\n",
    "* **Preprocessing steps**:\n",
    "    1. Crop the image (removing the sky at the top and the car front at the bottom).\n",
    "    2. Resize the image to the input shape used by the network model.\n",
    "    3. Convert the image from RGB to YUV (This is what the NVIDIA model does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a samples centrar image to show each augmentation effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[100]\n",
    "sample.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly choose an image**: From the center, left or right, and adjust\n",
    "    the steering angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, angle = choose_image(\n",
    "    sample.center_image_path(), \n",
    "    sample.left_image_path(), \n",
    "    sample.right_image_path(), \n",
    "    sample.steering_angle()\n",
    ")\n",
    "show_sample(img, angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly flip image**: Randomly flip the image left <-> right, and adjust the steering angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, angle = random_image_flip(sample.right_image(), sample.steering_angle())\n",
    "show_sample(img, angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly trasnlate**: Randomly shift the image vertically and horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, angle = random_image_translate(\n",
    "    sample.right_image(), \n",
    "    sample.steering_angle(),\n",
    "    range_x=100, \n",
    "    range_y=10\n",
    ")\n",
    "show_sample(img, angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random shadow**: Generates and adds random shadow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample(random_image_shadow(sample.center_image(), width=320, height=160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly brightness**: Randomly adjust brightness of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample(random_image_brightness(sample.center_image()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a samples centrar image to show each preprocessing step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(dataset[0].features[0])\n",
    "show_sample(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Randomly choose an image from the center, left or right, and adjust the steering angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choped_image = vertical_crop_image(image, top_offset=60, bottom_offset=25)\n",
    "show_sample(choped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Resize the image to the input shape used by the network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = resize_image(choped_image, 320, 160)\n",
    "show_sample(resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Convert the image from RGB to YUV (This is what the NVIDIA model does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample(rgb_to_yuv(resized_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train and validation data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_threshold = cfg['train']['augment']['threshold']\n",
    "translate_range_x = cfg['train']['augment']['translate_range_x']\n",
    "translate_range_y = cfg['train']['augment']['translate_range_y']\n",
    "batch_size = cfg['train']['batch_size']\n",
    "output_shape=[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image augment threshold: \", augment_threshold)\n",
    "print(\"Image augment translate_range_x: \", translate_range_x)\n",
    "print(\"Image augment translate_range_y: \", translate_range_y)\n",
    "print(\"Number of samples by batch: \", batch_size)\n",
    "print(\"Output shape: \", output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preprocessor=ImagePreprocessor(\n",
    "    top_offset=60,\n",
    "    bottom_offset=25,\n",
    "    input_shape=input_shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_augmenter = SampleAugmenter(\n",
    "    augment_threshold,\n",
    "    translate_range_x,\n",
    "    translate_range_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = SteeringWheelAngleDataGenerator(\n",
    "    dataset=train_dataset,\n",
    "    input_shape=input_shape,\n",
    "    output_shape=output_shape,\n",
    "    batch_size=batch_size,\n",
    "    sample_augmenter=sample_augmenter,\n",
    "    image_preprocessor=image_preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = SteeringWheelAngleDataGenerator(\n",
    "    dataset=validation_dataset,\n",
    "    input_shape=input_shape,\n",
    "    output_shape=output_shape,\n",
    "    batch_size=batch_size,\n",
    "    image_preprocessor=image_preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_factory = CheckpointFactory(path=cfg['train']['checkpoint_path'])\n",
    "\n",
    "checkpoint = checkpoint_factory.create(model_name=model.name, metric='val_loss')\n",
    "\n",
    "plot_losses = PlotLossesFactory.create(\n",
    "    plot_interval=1, \n",
    "    evaluate_interval=10,\n",
    "    x_val=None,\n",
    "    y_val_categorical=None\n",
    ")\n",
    "callbacks=[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Adam(lr=1.0e-4)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=30\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps per epoch**: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of unique samples of your dataset divided by the batch size.\n",
    "\n",
    "i.e.: When steps_per_epoch == 5 then model fit 5 baches por epoch and use 5 * batch_size samples.\n",
    "\n",
    "**samples_per_epoch = steps_per_epoch * batch_size**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    generator=train_generator,\n",
    "    validation_generator=validation_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Dropout](https://youtu.be/Ty6K6YiGdBs)\n",
    "* [Dropout RENDER](https://youtu.be/6DcImJS8uV8)\n",
    "* [Dropout Pt. 2 RENDER](https://youtu.be/8nG8zzJMbZw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introduction to Exponential Linear Unit](https://medium.com/@krishnakalyan3/introduction-to-exponential-linear-unit-d3e2904b366c)\n",
    "* [Which Activation Function Should I Use?](https://youtu.be/-7scQpJT7uo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [A detailed example of how to use data generators with Keras](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
